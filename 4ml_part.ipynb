{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd329b37-acbc-46d4-8ca0-69edb7cd3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890eba5d-53a7-4868-be60-bb45f16fc82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Body</th>\n",
       "      <th>Year</th>\n",
       "      <th>Price</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Steering wheel</th>\n",
       "      <th>Customs Clearance</th>\n",
       "      <th>Color</th>\n",
       "      <th>задний</th>\n",
       "      <th>передний</th>\n",
       "      <th>полный</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>13500000</td>\n",
       "      <td>0</td>\n",
       "      <td>89422.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>10000000</td>\n",
       "      <td>3</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>41500000</td>\n",
       "      <td>0</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>8399000</td>\n",
       "      <td>3</td>\n",
       "      <td>193250.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "      <td>3800000</td>\n",
       "      <td>3</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>40000000</td>\n",
       "      <td>0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>16000000</td>\n",
       "      <td>0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>12900000</td>\n",
       "      <td>0</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6617</th>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>11500000</td>\n",
       "      <td>0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>239</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>11500000</td>\n",
       "      <td>0</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6619 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Body  Year     Price  Transmission   Mileage  Volume  \\\n",
       "0        5     2  2015  13500000             0   89422.0     2.0   \n",
       "1        4     2  2012  10000000             3   44000.0     2.0   \n",
       "2        3     9  2018  41500000             0  142000.0     3.0   \n",
       "3        1     5  2011   8399000             3  193250.0     2.0   \n",
       "4        0    12  2012   3800000             3  140000.0     1.2   \n",
       "...    ...   ...   ...       ...           ...       ...     ...   \n",
       "6614   238     0  2015  40000000             0   80000.0     5.0   \n",
       "6615   239     2  2016  16000000             0   60000.0     2.0   \n",
       "6616   239     2  2014  12900000             0   94900.0     2.0   \n",
       "6617   239     2  2013  11500000             0   81000.0     2.0   \n",
       "6618   239     2  2013  11500000             0  139000.0     2.0   \n",
       "\n",
       "      Steering wheel  Customs Clearance  Color  задний  передний  полный  \n",
       "0                  0                  1      7       0         0       1  \n",
       "1                  0                  1     11       0         0       1  \n",
       "2                  0                  1     11       0         0       1  \n",
       "3                  0                  1      8       0         0       1  \n",
       "4                  0                  0      9       0         1       0  \n",
       "...              ...                ...    ...     ...       ...     ...  \n",
       "6614               0                  1      8       0         0       1  \n",
       "6615               0                  1      1       0         0       1  \n",
       "6616               0                  1      4       0         0       1  \n",
       "6617               0                  1      1       0         1       0  \n",
       "6618               0                  1     11       0         1       0  \n",
       "\n",
       "[6619 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed_data_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51308618-2e7e-4744-a151-e1efe51d2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc14f86-82a0-4ada-ae6d-40c49560d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features and target variable\n",
    "X = df.drop('Price', axis=1)  # Assuming 'Price' is the target variable\n",
    "y = df['Price']\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Applying PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d42327-1d3c-43fd-aad7-b420470d7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcf9e11-7d64-420a-b604-5122478eb5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.8033619186774112\n"
     ]
    }
   ],
   "source": [
    "max_acc=0\n",
    "ind=0\n",
    "for n in range(1,50):\n",
    "    knn = KNeighborsRegressor(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = r2_score(y_test, y_pred)  # R-squared as a measure of accuracy\n",
    "    if accuracy>max_acc:\n",
    "        max_acc=accuracy\n",
    "        ind=n\n",
    "print(ind, max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c84bfae-4bd6-4f29-9e68-f6637ccf010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'epsilon': 0.1, 'kernel': 'linear'}\n",
      "Best Score: 0.01182094046777602\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'C': [1, 10, 100],\n",
    "    'epsilon': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "svr = SVR()\n",
    "grid_search = GridSearchCV(svr, parameters, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40fa488-19e5-49bb-89a3-fee1b8615ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "0:\tlearn: 7922648.6010566\ttotal: 156ms\tremaining: 15.4s\n",
      "1:\tlearn: 7365459.0715446\ttotal: 166ms\tremaining: 8.14s\n",
      "2:\tlearn: 6863568.9161517\ttotal: 175ms\tremaining: 5.67s\n",
      "3:\tlearn: 6438326.5225385\ttotal: 185ms\tremaining: 4.44s\n",
      "4:\tlearn: 6067913.6474005\ttotal: 194ms\tremaining: 3.69s\n",
      "5:\tlearn: 5695888.2281079\ttotal: 204ms\tremaining: 3.19s\n",
      "6:\tlearn: 5414336.9453364\ttotal: 213ms\tremaining: 2.83s\n",
      "7:\tlearn: 5101252.3988760\ttotal: 223ms\tremaining: 2.56s\n",
      "8:\tlearn: 4846176.7733225\ttotal: 232ms\tremaining: 2.34s\n",
      "9:\tlearn: 4613642.5115516\ttotal: 241ms\tremaining: 2.17s\n",
      "10:\tlearn: 4415270.8924742\ttotal: 250ms\tremaining: 2.02s\n",
      "11:\tlearn: 4246371.6390291\ttotal: 259ms\tremaining: 1.9s\n",
      "12:\tlearn: 4078044.6208887\ttotal: 268ms\tremaining: 1.79s\n",
      "13:\tlearn: 3941680.6730172\ttotal: 277ms\tremaining: 1.7s\n",
      "14:\tlearn: 3800291.0273157\ttotal: 286ms\tremaining: 1.62s\n",
      "15:\tlearn: 3658595.6334210\ttotal: 297ms\tremaining: 1.56s\n",
      "16:\tlearn: 3549916.1840918\ttotal: 310ms\tremaining: 1.51s\n",
      "17:\tlearn: 3449273.5134678\ttotal: 334ms\tremaining: 1.52s\n",
      "18:\tlearn: 3369972.9351584\ttotal: 342ms\tremaining: 1.46s\n",
      "19:\tlearn: 3283017.4389384\ttotal: 351ms\tremaining: 1.4s\n",
      "20:\tlearn: 3217329.4539883\ttotal: 359ms\tremaining: 1.35s\n",
      "21:\tlearn: 3142281.0996525\ttotal: 368ms\tremaining: 1.3s\n",
      "22:\tlearn: 3081934.2590356\ttotal: 376ms\tremaining: 1.26s\n",
      "23:\tlearn: 3026443.4865734\ttotal: 385ms\tremaining: 1.22s\n",
      "24:\tlearn: 2988551.0780562\ttotal: 393ms\tremaining: 1.18s\n",
      "25:\tlearn: 2926835.8748160\ttotal: 401ms\tremaining: 1.14s\n",
      "26:\tlearn: 2870954.4545536\ttotal: 409ms\tremaining: 1.1s\n",
      "27:\tlearn: 2825031.2398621\ttotal: 417ms\tremaining: 1.07s\n",
      "28:\tlearn: 2786061.9229688\ttotal: 426ms\tremaining: 1.04s\n",
      "29:\tlearn: 2750864.3859111\ttotal: 434ms\tremaining: 1.01s\n",
      "30:\tlearn: 2708947.1048196\ttotal: 440ms\tremaining: 979ms\n",
      "31:\tlearn: 2676055.5230007\ttotal: 445ms\tremaining: 946ms\n",
      "32:\tlearn: 2647502.9493360\ttotal: 451ms\tremaining: 916ms\n",
      "33:\tlearn: 2613031.3811659\ttotal: 460ms\tremaining: 893ms\n",
      "34:\tlearn: 2586741.5653706\ttotal: 469ms\tremaining: 870ms\n",
      "35:\tlearn: 2563784.6139341\ttotal: 477ms\tremaining: 847ms\n",
      "36:\tlearn: 2541750.2073511\ttotal: 485ms\tremaining: 825ms\n",
      "37:\tlearn: 2520948.4878814\ttotal: 493ms\tremaining: 804ms\n",
      "38:\tlearn: 2498007.4408923\ttotal: 501ms\tremaining: 783ms\n",
      "39:\tlearn: 2475741.1578639\ttotal: 509ms\tremaining: 764ms\n",
      "40:\tlearn: 2459395.2389411\ttotal: 517ms\tremaining: 744ms\n",
      "41:\tlearn: 2437312.8549453\ttotal: 525ms\tremaining: 725ms\n",
      "42:\tlearn: 2410960.6619090\ttotal: 532ms\tremaining: 706ms\n",
      "43:\tlearn: 2384645.4086029\ttotal: 539ms\tremaining: 686ms\n",
      "44:\tlearn: 2370776.3691528\ttotal: 548ms\tremaining: 669ms\n",
      "45:\tlearn: 2355657.7617221\ttotal: 555ms\tremaining: 652ms\n",
      "46:\tlearn: 2345828.7327341\ttotal: 564ms\tremaining: 636ms\n",
      "47:\tlearn: 2333678.2587792\ttotal: 571ms\tremaining: 619ms\n",
      "48:\tlearn: 2315775.2724525\ttotal: 578ms\tremaining: 602ms\n",
      "49:\tlearn: 2302920.7309292\ttotal: 582ms\tremaining: 582ms\n",
      "50:\tlearn: 2288249.4005853\ttotal: 588ms\tremaining: 565ms\n",
      "51:\tlearn: 2270255.5630592\ttotal: 595ms\tremaining: 549ms\n",
      "52:\tlearn: 2259313.4691595\ttotal: 601ms\tremaining: 533ms\n",
      "53:\tlearn: 2245193.0814265\ttotal: 608ms\tremaining: 518ms\n",
      "54:\tlearn: 2235308.2205154\ttotal: 614ms\tremaining: 502ms\n",
      "55:\tlearn: 2228811.3413992\ttotal: 621ms\tremaining: 488ms\n",
      "56:\tlearn: 2217953.7521058\ttotal: 627ms\tremaining: 473ms\n",
      "57:\tlearn: 2206725.2862888\ttotal: 631ms\tremaining: 457ms\n",
      "58:\tlearn: 2194774.0057166\ttotal: 635ms\tremaining: 441ms\n",
      "59:\tlearn: 2184590.3978917\ttotal: 640ms\tremaining: 426ms\n",
      "60:\tlearn: 2179456.1564538\ttotal: 644ms\tremaining: 412ms\n",
      "61:\tlearn: 2170795.8844084\ttotal: 647ms\tremaining: 397ms\n",
      "62:\tlearn: 2163277.1174363\ttotal: 652ms\tremaining: 383ms\n",
      "63:\tlearn: 2160795.6628370\ttotal: 656ms\tremaining: 369ms\n",
      "64:\tlearn: 2153213.4067841\ttotal: 659ms\tremaining: 355ms\n",
      "65:\tlearn: 2145681.4486839\ttotal: 662ms\tremaining: 341ms\n",
      "66:\tlearn: 2134601.8570461\ttotal: 665ms\tremaining: 328ms\n",
      "67:\tlearn: 2126124.5477000\ttotal: 669ms\tremaining: 315ms\n",
      "68:\tlearn: 2119752.9145247\ttotal: 672ms\tremaining: 302ms\n",
      "69:\tlearn: 2108348.5794129\ttotal: 675ms\tremaining: 289ms\n",
      "70:\tlearn: 2100936.2492708\ttotal: 678ms\tremaining: 277ms\n",
      "71:\tlearn: 2088454.0980071\ttotal: 682ms\tremaining: 265ms\n",
      "72:\tlearn: 2088174.4245657\ttotal: 683ms\tremaining: 253ms\n",
      "73:\tlearn: 2083944.3513874\ttotal: 686ms\tremaining: 241ms\n",
      "74:\tlearn: 2074496.5520014\ttotal: 689ms\tremaining: 230ms\n",
      "75:\tlearn: 2067253.2632879\ttotal: 693ms\tremaining: 219ms\n",
      "76:\tlearn: 2057959.8883733\ttotal: 696ms\tremaining: 208ms\n",
      "77:\tlearn: 2047459.7577381\ttotal: 699ms\tremaining: 197ms\n",
      "78:\tlearn: 2041896.5221274\ttotal: 703ms\tremaining: 187ms\n",
      "79:\tlearn: 2035463.1587990\ttotal: 706ms\tremaining: 177ms\n",
      "80:\tlearn: 2031359.5342792\ttotal: 709ms\tremaining: 166ms\n",
      "81:\tlearn: 2025571.8895360\ttotal: 713ms\tremaining: 156ms\n",
      "82:\tlearn: 2016790.9538844\ttotal: 716ms\tremaining: 147ms\n",
      "83:\tlearn: 2006412.1594811\ttotal: 719ms\tremaining: 137ms\n",
      "84:\tlearn: 2003379.0577340\ttotal: 723ms\tremaining: 128ms\n",
      "85:\tlearn: 1989988.2638425\ttotal: 726ms\tremaining: 118ms\n",
      "86:\tlearn: 1985351.1280834\ttotal: 729ms\tremaining: 109ms\n",
      "87:\tlearn: 1978380.6244666\ttotal: 733ms\tremaining: 99.9ms\n",
      "88:\tlearn: 1967132.2501701\ttotal: 736ms\tremaining: 91ms\n",
      "89:\tlearn: 1959583.6550727\ttotal: 740ms\tremaining: 82.2ms\n",
      "90:\tlearn: 1951268.5237306\ttotal: 743ms\tremaining: 73.5ms\n",
      "91:\tlearn: 1945603.2421656\ttotal: 746ms\tremaining: 64.9ms\n",
      "92:\tlearn: 1941716.5831802\ttotal: 750ms\tremaining: 56.4ms\n",
      "93:\tlearn: 1932117.9522516\ttotal: 753ms\tremaining: 48.1ms\n",
      "94:\tlearn: 1925614.5202513\ttotal: 756ms\tremaining: 39.8ms\n",
      "95:\tlearn: 1921401.9488301\ttotal: 760ms\tremaining: 31.7ms\n",
      "96:\tlearn: 1912350.3197299\ttotal: 764ms\tremaining: 23.6ms\n",
      "97:\tlearn: 1901617.7330401\ttotal: 767ms\tremaining: 15.7ms\n",
      "98:\tlearn: 1893665.1684142\ttotal: 770ms\tremaining: 7.78ms\n",
      "99:\tlearn: 1890196.9041805\ttotal: 774ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'depth': 8, 'iterations': 100, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'iterations': [30, 50, 100]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "catboost = CatBoostRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=catboost, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b283a403-08f8-4838-a5c8-9414786db14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 5295, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 9080481.488196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Damir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Linear Regression': 0.5540396188146894,\n",
       " 'Random Forest': 0.8949464748778169,\n",
       " 'Support Vector Regressor': 0.058900323465795434,\n",
       " 'K-Nearest Neighbors': 0.8033619186774112,\n",
       " 'Decision Tree': 0.8301360967700739,\n",
       " 'Gradient Boosting': 0.8669955323743723,\n",
       " 'AdaBoost': 0.284308825632554,\n",
       " 'Bagging': 0.8798164531608794,\n",
       " 'Ridge Regression': 0.5540610618019511,\n",
       " 'Lasso Regression': 0.5540112798961466,\n",
       " 'ElasticNet': 0.5479896779151112,\n",
       " 'XGBoost': 0.9040174472505607,\n",
       " 'LightGBM': 0.9078528004477533,\n",
       " 'CatBoost': 0.9242536944671232,\n",
       " 'PLSRegression': -64.28745050825692,\n",
       " 'MLPRegressor': 0.6976598265260776,\n",
       " 'ExtraTreesRegressor': 0.9119551807897307}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Support Vector Regressor': SVR(C=100, epsilon = 0.1, kernel = 'linear'),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=13),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'Bagging': BaggingRegressor(random_state=42),\n",
    "    'Ridge Regression': Ridge(random_state=42),\n",
    "    'Lasso Regression': Lasso(random_state=42),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=0),\n",
    "    'PLSRegression': PLSRegression(n_components = 12),\n",
    "    'MLPRegressor': MLPRegressor(hidden_layer_sizes = 50, alpha = 0.001, solver = 'lbfgs', learning_rate = 'adaptive'),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "\n",
    "}\n",
    "\n",
    "# Training and evaluating models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = r2_score(y_test, y_pred)  # R-squared as a measure of accuracy\n",
    "    results[name] = accuracy\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565e5cab-7039-45ba-8d8a-b06b81a3a3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.540\n",
      "Model:                            OLS   Adj. R-squared:                  0.539\n",
      "Method:                 Least Squares   F-statistic:                     705.4\n",
      "Date:                Tue, 12 Dec 2023   Prob (F-statistic):               0.00\n",
      "Time:                        16:39:55   Log-Likelihood:            -1.1220e+05\n",
      "No. Observations:                6619   AIC:                         2.244e+05\n",
      "Df Residuals:                    6607   BIC:                         2.245e+05\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const             -1.261e+09   3.08e+07    -40.979      0.000   -1.32e+09    -1.2e+09\n",
      "Name               3442.2350    939.759      3.663      0.000    1600.004    5284.466\n",
      "Body               4.646e+04   2.84e+04      1.633      0.102   -9306.406    1.02e+05\n",
      "Year               8.343e+05   2.03e+04     41.024      0.000    7.94e+05    8.74e+05\n",
      "Transmission      -9.227e+05   8.21e+04    -11.245      0.000   -1.08e+06   -7.62e+05\n",
      "Mileage              -9.1960      0.992     -9.275      0.000     -11.140      -7.252\n",
      "Volume              4.11e+06   9.15e+04     44.904      0.000    3.93e+06    4.29e+06\n",
      "Steering wheel     1.474e+06   5.98e+05      2.467      0.014    3.03e+05    2.65e+06\n",
      "Customs Clearance  1.325e+06   2.61e+05      5.075      0.000    8.13e+05    1.84e+06\n",
      "Color              9.012e+04   1.73e+04      5.196      0.000    5.61e+04    1.24e+05\n",
      "задний            -4.209e+08   1.02e+07    -41.094      0.000   -4.41e+08   -4.01e+08\n",
      "передний           -4.21e+08   1.03e+07    -40.999      0.000   -4.41e+08   -4.01e+08\n",
      "полный            -4.189e+08   1.03e+07    -40.821      0.000   -4.39e+08   -3.99e+08\n",
      "==============================================================================\n",
      "Omnibus:                     7281.606   Durbin-Watson:                   1.315\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           880674.191\n",
      "Skew:                           5.488   Prob(JB):                         0.00\n",
      "Kurtosis:                      58.433   Cond. No.                     8.45e+19\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.53e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbfd45ba-39b2-4b67-bb5d-81da6b54f839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Damir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Damir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Damir\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "133/133 [==============================] - 2s 4ms/step - loss: 159156338163712.0000 - val_loss: 140567426105344.0000\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 159144409563136.0000 - val_loss: 140542260281344.0000\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 159094866444288.0000 - val_loss: 140466485985280.0000\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 158977895694336.0000 - val_loss: 140312596971520.0000\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 158772190248960.0000 - val_loss: 140062683561984.0000\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 158460066922496.0000 - val_loss: 139699070959616.0000\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 158022215139328.0000 - val_loss: 139200905084928.0000\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 157424342269952.0000 - val_loss: 138565912625152.0000\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 156701042933760.0000 - val_loss: 137775605088256.0000\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 155796784545792.0000 - val_loss: 136810353131520.0000\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 154704906551296.0000 - val_loss: 135687647002624.0000\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 153455574384640.0000 - val_loss: 134380534104064.0000\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 152080144662528.0000 - val_loss: 132925404217344.0000\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 150512347381760.0000 - val_loss: 131304414773248.0000\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 148713511059456.0000 - val_loss: 129516374589440.0000\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 146795036409856.0000 - val_loss: 127497010151424.0000\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 144650555883520.0000 - val_loss: 125395806453760.0000\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 142355080413184.0000 - val_loss: 123106362392576.0000\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 139827215335424.0000 - val_loss: 120616548040704.0000\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 137431848321024.0000 - val_loss: 118088565522432.0000\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 134752652754944.0000 - val_loss: 115357452861440.0000\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 131816598011904.0000 - val_loss: 112548284203008.0000\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 128892606087168.0000 - val_loss: 109600795787264.0000\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 125652162314240.0000 - val_loss: 106518494052352.0000\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 122455179919360.0000 - val_loss: 103398904954880.0000\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 119184587489280.0000 - val_loss: 100191671681024.0000\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 115692208652288.0000 - val_loss: 96912497704960.0000\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 112228065869824.0000 - val_loss: 93606891225088.0000\n",
      "Epoch 29/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 108956961734656.0000 - val_loss: 90258469289984.0000\n",
      "Epoch 30/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 105286794739712.0000 - val_loss: 86955203231744.0000\n",
      "Epoch 31/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 102014776246272.0000 - val_loss: 83597721600000.0000\n",
      "Epoch 32/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 98367417876480.0000 - val_loss: 80296049377280.0000\n",
      "Epoch 33/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 94785574535168.0000 - val_loss: 77063214071808.0000\n",
      "Epoch 34/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 91917182304256.0000 - val_loss: 73869016694784.0000\n",
      "Epoch 35/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 88462107607040.0000 - val_loss: 70739109609472.0000\n",
      "Epoch 36/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 85113106857984.0000 - val_loss: 67684091822080.0000\n",
      "Epoch 37/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 81776571580416.0000 - val_loss: 64745424027648.0000\n",
      "Epoch 38/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 78605635813376.0000 - val_loss: 61873592467456.0000\n",
      "Epoch 39/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 76262211059712.0000 - val_loss: 59171424698368.0000\n",
      "Epoch 40/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 73615328411648.0000 - val_loss: 56575960023040.0000\n",
      "Epoch 41/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 70016850460672.0000 - val_loss: 54134149480448.0000\n",
      "Epoch 42/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 67337843638272.0000 - val_loss: 51813478825984.0000\n",
      "Epoch 43/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 65767756267520.0000 - val_loss: 49661654073344.0000\n",
      "Epoch 44/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 62515325173760.0000 - val_loss: 47638338600960.0000\n",
      "Epoch 45/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 61223823474688.0000 - val_loss: 45801178923008.0000\n",
      "Epoch 46/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 59302672859136.0000 - val_loss: 44116557692928.0000\n",
      "Epoch 47/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 57539953688576.0000 - val_loss: 42503508066304.0000\n",
      "Epoch 48/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 55664793616384.0000 - val_loss: 41073174904832.0000\n",
      "Epoch 49/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 53998941896704.0000 - val_loss: 39760483581952.0000\n",
      "Epoch 50/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 52808971714560.0000 - val_loss: 38593707900928.0000\n",
      "Epoch 51/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 52182112010240.0000 - val_loss: 37556364247040.0000\n",
      "Epoch 52/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 50764588253184.0000 - val_loss: 36598607511552.0000\n",
      "Epoch 53/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 49797880872960.0000 - val_loss: 35770106642432.0000\n",
      "Epoch 54/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 48745693577216.0000 - val_loss: 35005958979584.0000\n",
      "Epoch 55/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 48012256608256.0000 - val_loss: 34321708613632.0000\n",
      "Epoch 56/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 47302039306240.0000 - val_loss: 33692133097472.0000\n",
      "Epoch 57/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 46536855650304.0000 - val_loss: 33126856261632.0000\n",
      "Epoch 58/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 45586212454400.0000 - val_loss: 32595085623296.0000\n",
      "Epoch 59/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 45097324380160.0000 - val_loss: 32137256370176.0000\n",
      "Epoch 60/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 44788657160192.0000 - val_loss: 31713549877248.0000\n",
      "Epoch 61/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 43868800155648.0000 - val_loss: 31317766963200.0000\n",
      "Epoch 62/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 42946632089600.0000 - val_loss: 30963348275200.0000\n",
      "Epoch 63/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 43087350988800.0000 - val_loss: 30639820636160.0000\n",
      "Epoch 64/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 42825722888192.0000 - val_loss: 30341077139456.0000\n",
      "Epoch 65/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 42276881432576.0000 - val_loss: 30058838228992.0000\n",
      "Epoch 66/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 42359509221376.0000 - val_loss: 29796895555584.0000\n",
      "Epoch 67/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 41555062685696.0000 - val_loss: 29551371485184.0000\n",
      "Epoch 68/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 41518823899136.0000 - val_loss: 29329205493760.0000\n",
      "Epoch 69/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 42283483267072.0000 - val_loss: 29107997900800.0000\n",
      "Epoch 70/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 40794559873024.0000 - val_loss: 28899148824576.0000\n",
      "Epoch 71/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 41239332257792.0000 - val_loss: 28700909240320.0000\n",
      "Epoch 72/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 39976033058816.0000 - val_loss: 28519723696128.0000\n",
      "Epoch 73/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 40800222183424.0000 - val_loss: 28330363453440.0000\n",
      "Epoch 74/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 39794650382336.0000 - val_loss: 28148647329792.0000\n",
      "Epoch 75/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 39874069528576.0000 - val_loss: 27985948180480.0000\n",
      "Epoch 76/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 39778338734080.0000 - val_loss: 27825736253440.0000\n",
      "Epoch 77/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 39341686521856.0000 - val_loss: 27672851775488.0000\n",
      "Epoch 78/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 39474734039040.0000 - val_loss: 27533420527616.0000\n",
      "Epoch 79/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 39417548898304.0000 - val_loss: 27387100135424.0000\n",
      "Epoch 80/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 39176892317696.0000 - val_loss: 27256506286080.0000\n",
      "Epoch 81/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 39331234316288.0000 - val_loss: 27114709450752.0000\n",
      "Epoch 82/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 39094604267520.0000 - val_loss: 26975328534528.0000\n",
      "Epoch 83/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 38416263675904.0000 - val_loss: 26848312426496.0000\n",
      "Epoch 84/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 39098907623424.0000 - val_loss: 26729766715392.0000\n",
      "Epoch 85/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 38232678989824.0000 - val_loss: 26612145848320.0000\n",
      "Epoch 86/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 38425092685824.0000 - val_loss: 26480817995776.0000\n",
      "Epoch 87/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 38307094331392.0000 - val_loss: 26370568617984.0000\n",
      "Epoch 88/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 38360974360576.0000 - val_loss: 26251458772992.0000\n",
      "Epoch 89/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 38398697930752.0000 - val_loss: 26141100343296.0000\n",
      "Epoch 90/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 37778612027392.0000 - val_loss: 26019541024768.0000\n",
      "Epoch 91/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 38112189218816.0000 - val_loss: 25930326081536.0000\n",
      "Epoch 92/100\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 37398918463488.0000 - val_loss: 25825466384384.0000\n",
      "Epoch 93/100\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 37123973447680.0000 - val_loss: 25732925358080.0000\n",
      "Epoch 94/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 37634608988160.0000 - val_loss: 25637020499968.0000\n",
      "Epoch 95/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 37538110636032.0000 - val_loss: 25535969230848.0000\n",
      "Epoch 96/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 36966674464768.0000 - val_loss: 25427892502528.0000\n",
      "Epoch 97/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 37152490520576.0000 - val_loss: 25322139418624.0000\n",
      "Epoch 98/100\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 36872222932992.0000 - val_loss: 25240245633024.0000\n",
      "Epoch 99/100\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 36637048307712.0000 - val_loss: 25153132036096.0000\n",
      "Epoch 100/100\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 37252453367808.0000 - val_loss: 25070843985920.0000\n",
      "42/42 [==============================] - 0s 2ms/step\n",
      "R-squared for Neural Network: 0.5280942275181235\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='linear')  # For regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "print('R-squared for Neural Network:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7146f-471f-498a-a678-e9d344970784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
